{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "retired-leader",
   "metadata": {},
   "source": [
    "# Topic 2: Cloud Optimized Data & STAC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-madrid",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-upset",
   "metadata": {},
   "source": [
    "In this example we will access the NASA HLS assets, which are archived in cloud optimize geoTIFF (COG) format in the LP DAAC Cumulus cloud space. The COGs can be used like any other geoTIFF file, but have some added features that make them more efficient within the cloud data access paradigm. These features include: overviews and internal tiling. Below we will demonstrate how to leverage these features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-array",
   "metadata": {},
   "source": [
    "## Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import defaultdict    # https://stackoverflow.com/questions/26367812/appending-to-list-in-python-dictionary\n",
    "import requests\n",
    "import rasterio as rio                 # https://rasterio.readthedocs.io/en/latest/\n",
    "from rasterio.plot import show\n",
    "import rioxarray                       # https://corteva.github.io/rioxarray/stable/index.html\n",
    "import geopandas\n",
    "import pyproj\n",
    "from pyproj import Proj\n",
    "from shapely.ops import transform\n",
    "import geoviews as gv\n",
    "from cartopy import crs\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "gv.extension('bokeh', 'matplotlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-dubai",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-agent",
   "metadata": {},
   "source": [
    "## Set GDAL Configuration Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-privacy",
   "metadata": {},
   "source": [
    "**First, let us set the gdal configuration options for this session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = dict(GDAL_DISABLE_READDIR_ON_OPEN='EMPTY_DIR', \n",
    "                   AWS_NO_SIGN_REQUEST='YES',\n",
    "                   GDAL_MAX_RAW_BLOCK_CACHE_SIZE='200000000',\n",
    "                   GDAL_SWATH_SIZE='200000000',\n",
    "                   VSI_CURL_CACHE_SIZE='200000000',\n",
    "                   GDAL_HTTP_COOKIEFILE=os.path.expanduser('~/cookies.txt'),\n",
    "                   GDAL_HTTP_COOKIEJAR=os.path.expanduser('~/cookies.txt'))\n",
    "\n",
    "\n",
    "os.environ.update(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-romance",
   "metadata": {},
   "source": [
    "## Working with Overviews "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-brief",
   "metadata": {},
   "source": [
    "**Access a single HLS asset to identify the overview levels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-buffalo",
   "metadata": {},
   "outputs": [],
   "source": [
    "foa_url = \"https://lpdaac.earthdata.nasa.gov/lp-prod-protected/HLSS30.015/HLS.S30.T13TGF.2020191T172901.v1.5.B04.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open(foa_url) as src:\n",
    "    hls_ov_levels = src.overviews(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_ov_levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-geology",
   "metadata": {},
   "source": [
    "**Request the second overview level from the asset (`overview_level=1`)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "with rioxarray.open_rasterio(foa_url, masked=True, overview_level=1, chunks=True) as src:    # https://nbviewer.jupyter.org/gist/rsignell-usgs/f4dd62ad1274c5b5ed69e5a6b81c1295 & http://rasterio.readthedocs.io/en/latest/topics/resampling.html\n",
    "        fig, ax = plt.subplots(1, figsize=(12, 12))\n",
    "        print(src)\n",
    "        show(src, cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-quantum",
   "metadata": {},
   "source": [
    "**Request the last overview level (`overview_level=3`)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "with rioxarray.open_rasterio(foa_url, masked=True, overview_level=3, chunks=True) as src:\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 12))\n",
    "    print(src)\n",
    "    show(src, cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-dinner",
   "metadata": {},
   "source": [
    "## Requesting Spatial Subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-toolbox",
   "metadata": {},
   "source": [
    "![COG tiling example](img/COG_Smile_AOI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-walnut",
   "metadata": {},
   "source": [
    "**Now, we will read in a geojson file and use its bounding box to clip the cloud asset in later steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-salad",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "field = geopandas.read_file('./data/ne_w_agfields.geojson')\n",
    "type(field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldShape = field['geometry'][0]    # Define the geometry as a shapely polygon\n",
    "fieldShape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-short",
   "metadata": {},
   "source": [
    "Get the lower-left and upper-right coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldShape.bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-graph",
   "metadata": {},
   "source": [
    "Use geoviews to combine a basemap with the shapely polygon of our Region of Interest (ROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = gv.tile_sources.EsriImagery.opts(width=650, height=500)\n",
    "farmField = gv.Polygons(fieldShape).opts(line_color='yellow', line_width=10, color=None)\n",
    "base * farmField"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-report",
   "metadata": {},
   "source": [
    "### Requests an area of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-texture",
   "metadata": {},
   "source": [
    "**Transform coordinates from lat lon (units = dd) to UTM (units = m)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open(foa_url) as src:\n",
    "    hls_proj = src.crs.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_CRS = Proj('+proj=longlat +datum=WGS84 +no_defs', preserve_units=True)   # Source coordinate system of the ROI\n",
    "project = pyproj.Transformer.from_proj(geo_CRS, hls_proj)                    # Set up the transformation\n",
    "fsUTM = transform(project.transform, fieldShape)                             # Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-rogers",
   "metadata": {},
   "source": [
    "**Print the transformed bounds (now in meters)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsUTM.bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-parliament",
   "metadata": {},
   "source": [
    "**Use fsUTM to subset the source HLS tile**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-combination",
   "metadata": {},
   "source": [
    "**Requests data at full extent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-limitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "rds = rioxarray.open_rasterio(foa_url, masked=True, chunks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "rds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-detective",
   "metadata": {},
   "source": [
    "**Print the spatial reference attribute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rds.spatial_ref\n",
    "rds.spatial_ref.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-median",
   "metadata": {},
   "source": [
    "**Plot data at full extent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "rds[0].hvplot.image(x = 'x', y = 'y', crs = hls_proj, rasterize=True, cmap='Reds', width=800, height=600, colorbar=True, tiles = 'ESRI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-project",
   "metadata": {},
   "source": [
    "**Request data that intersects with the input geoJSON boundary only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_clipped = rioxarray.open_rasterio(foa_url, masked=True).rio.clip([fsUTM])    # Note: fsUTM must be in a list\n",
    "rds_clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_clipped[0].hvplot.image(x = 'x', y = 'y', crs = hls_proj, rasterize=True, cmap='Reds', width=800, height=600, colorbar=True, tiles = 'ESRI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-durham",
   "metadata": {},
   "source": [
    "**Add the field boudary to the clipped image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_clipped[0].hvplot.image(x = 'x', y = 'y', crs = hls_proj, rasterize=True, cmap='Reds', width=800, height=600, colorbar=True, tiles = 'ESRI') * farmField"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-holiday",
   "metadata": {},
   "source": [
    "**Get the Geotransformation information for the full tile**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "rds.spatial_ref.GeoTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-accommodation",
   "metadata": {},
   "source": [
    "**Geotransformation information for the clipped image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_clipped.spatial_ref.GeoTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-prague",
   "metadata": {},
   "source": [
    "### Request data for a point of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Transformer\n",
    "\n",
    "# convert coordinate to raster projection\n",
    "lon = -101.66786\n",
    "lat = 41.05679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer.from_crs(\"EPSG:4326\", rioxarray.open_rasterio(foa_url, masked=True).rio.crs, always_xy=True)\n",
    "xx, yy = transformer.transform(lon, lat)\n",
    "print(f'X,Y in source units: {xx},{yy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get value from grid\n",
    "value = rds.sel(x=xx, y=yy, method=\"nearest\").values\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-guinea",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- https://nbviewer.jupyter.org/gist/rsignell-usgs/f4dd62ad1274c5b5ed69e5a6b81c1295  \n",
    "- http://rasterio.readthedocs.io/en/latest/topics/resampling.html  \n",
    "- https://gis.stackexchange.com/questions/358036/extracting-data-from-a-raster/358058#358058"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-techno",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-foundation",
   "metadata": {},
   "source": [
    "## STAC...Because it's that cool!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-world",
   "metadata": {},
   "source": [
    "NASA's CMR STAC does not allow for querries accross the entire NASA catalog. Users must execute searches within provider catalogs (e.g., LPCLOUD) to find the STAC Items they are searching for. All the providers can be found here: <https://cmr.earthdata.nasa.gov/stac/>. In this exercise, we will query the **LPCLOUD** provider to identify STAC Items from the Harmonized Landsat Sentinel-2 (HLS) collection that fall within our area of interest and within our specified time range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-cowboy",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmr_stac_search = 'https://cmr.earthdata.nasa.gov/stac/LPCLOUD/search'  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-graph",
   "metadata": {},
   "source": [
    "**Specify the search criteria we are interested in**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-minister",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'limit': 100,\n",
    "    'bbox': '-101.67271614074707,41.04754380304359,-101.65344715118408,41.06213891056728',\n",
    "    'datetime': '2020-01-01T00:00:00Z/2021-01-01T23:59:59Z',\n",
    "    'collections': ['HLSS30.v1.5', 'HLSL30.v1.5']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_items = requests.post(cmr_stac_search, json=params).json()['features']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-layer",
   "metadata": {},
   "source": [
    "**Execute a POST request to query the HLS collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the HLSS30 and HLSL30 items of interest:\n",
    "hls_items = requests.post(cmr_stac_search, json=params).json()['features']  # Send POST request with S30 and L30 collections included\n",
    "print(f\"The search query returns {len(hls_items)} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-adventure",
   "metadata": {},
   "source": [
    "**Print a single STAC Item**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_items[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-gregory",
   "metadata": {},
   "source": [
    "**Create of list of links for the desired bands**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "evi_band_links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in hls_items:\n",
    "    if i['collection'] == 'HLSS30.v1.5':\n",
    "        evi_bands = ['B8A', 'B04', 'B02', 'Fmask'] # NIR RED BLUE Quality for S30\n",
    "    else:\n",
    "        evi_bands = ['B05', 'B04', 'B02', 'Fmask'] # NIR RED BLUE Quality for L30\n",
    "        \n",
    "    for a in i['assets']:\n",
    "        if any(b==a for b in evi_bands):\n",
    "            evi_band_links.append(i['assets'][a]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(evi_band_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-arena",
   "metadata": {},
   "source": [
    "We can see in the list of links that we have multiple tiles that intersect with our region of interest. Since these represent neighboring UTM zones, we will split them the list of links into seperate lists for each tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_dicts = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-perception",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in evi_band_links:\n",
    "    tile = l.split('.')[-6]\n",
    "    tile_dicts[tile].append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_dicts.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-lexington",
   "metadata": {},
   "source": [
    "**Create a list of links for each tile**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_links_T14TKL = tile_dicts['T14TKL']\n",
    "tile_links_T13TGF = tile_dicts['T13TGF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tile_links_T13TGF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_links_T13TGF[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-dispatch",
   "metadata": {},
   "source": [
    "**Split the links by band**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_dicts = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in tile_links_T13TGF:\n",
    "    band = b.split('.')[-2]\n",
    "    bands_dicts[band].append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_dicts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bands_dicts['B04'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_dicts['B04'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-signature",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- https://stackoverflow.com/questions/46899337/convert-raster-time-series-of-multiple-geotiff-images-to-netcdf\n",
    "- https://medium.com/@bonnefond.virginie/handling-multi-temporal-satellite-images-with-xarray-30d142d3391\n",
    "- https://docs.dea.ga.gov.au/notebooks/Frequently_used_code/Opening_GeoTIFFs_NetCDFs.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-intake",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-conservative",
   "metadata": {},
   "source": [
    "# [Next: Topic 3 - Data Proximate Compute](Topic_3__Data_Proximate_Compute.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pangeo] *",
   "language": "python",
   "name": "conda-env-pangeo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
